{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Based on our data analysis in the exploration.ipynb notebook, we will now build a model to predict the target label based on input features. We will use a neural network model.\n",
    "\n",
    "We'll also build a preprocessing pipeline to transform the data before feeding it into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 23:41:39.324608: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-13 23:41:39.378051: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-13 23:41:39.378091: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-13 23:41:39.378122: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-13 23:41:39.387844: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-13 23:41:39.389265: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-13 23:41:40.759574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-13 23:41:42.406336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-13 23:41:42.406914: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_CSV = 'data/train.csv'\n",
    "TEST_CSV = 'data/test.csv'\n",
    "\n",
    "drop_cols = [\"Vicuna\", \"Wallaby\", \"Turkey\", \"Tick\"]\n",
    "\n",
    "def proc_pipeline(filename: str, cols=None):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.drop(columns=drop_cols)\n",
    "    df = df.astype({'Tiglon': 'string'})\n",
    "    df.loc[df['Tiglon'].isnull(), 'Tiglon'] = 'True'\n",
    "\n",
    "    numerical_cols = df.select_dtypes(include='number').columns.drop('target')\n",
    "    categorical_cols = df.select_dtypes(exclude='number').columns\n",
    "\n",
    "    # One-hot encoding\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_cols)\n",
    "\n",
    "    # merge numerical and ohe columns\n",
    "    df = pd.concat([df[numerical_cols], df_encoded], axis=1)\n",
    "\n",
    "    # drop columns that are not in training set\n",
    "    if cols is not None:\n",
    "        extra_cols = set(df.columns) - set(cols)\n",
    "        df = df.drop(columns=extra_cols)\n",
    "\n",
    "    weight_0 = 1 - (df['target']==0).sum() / df.shape[0]\n",
    "    weight_1 = 1 - weight_0\n",
    "    # calculate class weights\n",
    "    class_weights = {\n",
    "        0: weight_0,\n",
    "        1: weight_1\n",
    "    }\n",
    "\n",
    "    x = tf.convert_to_tensor(df.drop(columns=['target']).values, dtype=tf.float32)\n",
    "    y = tf.convert_to_tensor(df['target'].values, dtype=tf.int32)\n",
    "    return x, y, class_weights, df.columns\n",
    "\n",
    "X_train, y_train, class_weights, train_cols = proc_pipeline(TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and adapt a normalization layer\n",
    "normalizer = tf.keras.layers.Normalization()\n",
    "normalizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 2s 10ms/step - loss: 3.0452 - accuracy: 0.8399\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1134 - accuracy: 0.8943\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0976 - accuracy: 0.8963\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0932 - accuracy: 0.8999\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0903 - accuracy: 0.9009\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0890 - accuracy: 0.9028\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0861 - accuracy: 0.9039\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0863 - accuracy: 0.9009\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0844 - accuracy: 0.9048\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0827 - accuracy: 0.9090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fcdbd86abf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5374284386634827, 0.7497575283050537]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test, _, _ = proc_pipeline(TEST_CSV, train_cols)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to achieve an accuracy of 74.98% on the test set using a 4-layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homework-zmPiI6Jn-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
